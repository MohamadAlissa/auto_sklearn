{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfrk3fKvMPNP"
      },
      "source": [
        "# AutoML\n",
        "AutoML is an automated way to choose the best machine learning algorithm for your problem with the best set of parameters. In this tutorial, we will show you how to run AutoML on a simple classification problem and then use the best classifier found to make some predictions.\n",
        "\n",
        "## Notice:\n",
        "You can use the AutoML library for regression problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf94T4KJKsvt"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Z7dH8ojSzjwf"
      },
      "outputs": [],
      "source": [
        "def install_packages():\n",
        "  !pip install auto-sklearn\n",
        "   \n",
        "\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "  import autosklearn.classification\n",
        "except:\n",
        "  install_packages()\n",
        "  import autosklearn.classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLhK686FKxj1"
      },
      "source": [
        "# Create a classification problem\n",
        "This is a simple classification problem. At this stage, you can define your classifiation problem. The output of this stage should be your training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pm6fNFr3w19",
        "outputId": "14a879b5-f46a-41a8-8c0a-42b90cd7ba83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training input data shape:  (112, 5)\n",
            "Training output data shape:  (112,)\n",
            "Testing data shape:  (38, 5)\n",
            "Testing data shape:  (38,)\n"
          ]
        }
      ],
      "source": [
        "X, y = make_classification(n_samples=150, n_classes=3,\n",
        "                            n_features=5, n_informative=3, n_redundant=0,\n",
        "                            random_state=0)\n",
        "x_train, x_test, y_train , y_test = train_test_split(X,y)\n",
        "print('Training input data shape: ', x_train.shape)\n",
        "print('Training output data shape: ', y_train.shape)\n",
        "print('Testing data shape: ', x_test.shape)\n",
        "print('Testing data shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZwGxzHKK7ZE"
      },
      "source": [
        "# Define AutoML object with time limits\n",
        "Choosing the best algorithm and best set of parameters is an optimisation problem. We might don't reach the optimal algorithm and set of parameters for our problem, but we will get a good enough solution. Thus, you need to specify the time limits for the optimisation problem and each hyper-parameter tunning run.\n",
        "\n",
        "If  you have a regression problem, then you can use  `autosklearn.regression.AutoSklearnRegressor`. [Here is an example](https://automl.github.io/auto-sklearn/master/examples/20_basic/example_regression.html#sphx-glr-examples-20-basic-example-regression-py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3KjoLkMIzlmX"
      },
      "outputs": [],
      "source": [
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "                                                          time_left_for_this_task=60, # in seconds\n",
        "                                                          per_run_time_limit=30 # in seconds\n",
        "                                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtem_RcFLF2B"
      },
      "source": [
        "# Train the AutoML object on the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqQw7o2T3OQq",
        "outputId": "b0970e0b-560a-4572-e279-8c49d5a8549a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2022-08-06 13:03:57,792:Client-AutoML(1):sklearn_classification_dataset] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AutoSklearnClassifier(per_run_time_limit=30, time_left_for_this_task=60)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automl.fit(x_train, y_train, dataset_name='sklearn_classification_dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvb8RLYuP5M7"
      },
      "source": [
        "# Check the classifiers that are investigated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INwWT34IOrz4",
        "outputId": "4c0c6156-ed0a-4244-827e-e2b9174371e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ExtraTreesClassifier(criterion='entropy', max_features=15, min_samples_leaf=2,\n",
            "                     min_samples_split=20, n_estimators=512, n_jobs=1,\n",
            "                     random_state=1, warm_start=True)\n",
            "\n",
            "HistGradientBoostingClassifier(early_stopping=False,\n",
            "                               l2_regularization=4.821686883442146e-05,\n",
            "                               learning_rate=0.10161621495242192, max_iter=512,\n",
            "                               max_leaf_nodes=535, min_samples_leaf=10,\n",
            "                               n_iter_no_change=0, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)\n",
            "\n",
            "HistGradientBoostingClassifier(early_stopping=False,\n",
            "                               l2_regularization=1.0647401999412075e-10,\n",
            "                               learning_rate=0.08291320147381159, max_iter=512,\n",
            "                               max_leaf_nodes=39, n_iter_no_change=0,\n",
            "                               random_state=1, validation_fraction=None,\n",
            "                               warm_start=True)\n",
            "\n",
            "MLPClassifier(alpha=4.2841884333778574e-06, beta_1=0.999, beta_2=0.9,\n",
            "              hidden_layer_sizes=(263, 263, 263),\n",
            "              learning_rate_init=0.0011804284312897009, max_iter=256,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)\n",
            "\n",
            "ExtraTreesClassifier(max_features=5, min_samples_leaf=3, min_samples_split=11,\n",
            "                     n_estimators=512, n_jobs=1, random_state=1,\n",
            "                     warm_start=True)\n",
            "\n",
            "RandomForestClassifier(max_features=1, min_samples_split=6, n_estimators=512,\n",
            "                       n_jobs=1, random_state=1, warm_start=True)\n",
            "\n",
            "MLPClassifier(alpha=0.02847755502162456, beta_1=0.999, beta_2=0.9,\n",
            "              hidden_layer_sizes=(123, 123),\n",
            "              learning_rate_init=0.000421568792103947, max_iter=256,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)\n",
            "\n",
            "RandomForestClassifier(criterion='entropy', max_features=1, n_estimators=512,\n",
            "                       n_jobs=1, random_state=1, warm_start=True)\n",
            "\n",
            "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
            "                   learning_rate=0.046269426995092074, n_estimators=406,\n",
            "                   random_state=1)\n",
            "\n",
            "HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=0.005326508887463406,\n",
            "                               learning_rate=0.060800813211425456, max_iter=512,\n",
            "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
            "                               n_iter_no_change=5, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)\n",
            "\n",
            "PassiveAggressiveClassifier(C=0.14833233294431605, average=True,\n",
            "                            loss='squared_hinge', max_iter=64, random_state=1,\n",
            "                            tol=0.00016482166646253793, warm_start=True)\n",
            "\n",
            "PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
            "                            max_iter=1024, random_state=1,\n",
            "                            tol=4.631073253805713e-05, warm_start=True)\n",
            "\n",
            "HistGradientBoostingClassifier(early_stopping=False, l2_regularization=1e-10,\n",
            "                               learning_rate=0.16262682406125173, max_iter=512,\n",
            "                               max_leaf_nodes=66, n_iter_no_change=0,\n",
            "                               random_state=1, validation_fraction=None,\n",
            "                               warm_start=True)\n",
            "\n",
            "RandomForestClassifier(criterion='entropy', max_features=4, min_samples_leaf=7,\n",
            "                       n_estimators=512, n_jobs=1, random_state=1,\n",
            "                       warm_start=True)\n",
            "\n",
            "RandomForestClassifier(max_features=3, min_samples_leaf=15, min_samples_split=3,\n",
            "                       n_estimators=512, n_jobs=1, random_state=1,\n",
            "                       warm_start=True)\n",
            "\n",
            "SVC(C=1198.7850746967626, cache_size=1885.6953125, gamma=0.015219182148092949,\n",
            "    max_iter=-1.0, random_state=1, tol=0.040610448809956276)\n",
            "\n",
            "RandomForestClassifier(criterion='entropy', max_features=13, min_samples_leaf=3,\n",
            "                       min_samples_split=12, n_estimators=512, n_jobs=1,\n",
            "                       random_state=1, warm_start=True)\n",
            "\n",
            "MLPClassifier(activation='tanh', alpha=0.00021148999718383549, beta_1=0.999,\n",
            "              beta_2=0.9, hidden_layer_sizes=(113, 113, 113),\n",
            "              learning_rate_init=0.0007452270241186694, max_iter=128,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)\n",
            "\n",
            "RandomForestClassifier(criterion='entropy', max_features=15, n_estimators=512,\n",
            "                       n_jobs=1, random_state=1, warm_start=True)\n",
            "\n",
            "LinearSVC(C=999.897948630207, class_weight='balanced', dual=False,\n",
            "          intercept_scaling=1.0, random_state=1, tol=7.067903490334549e-05)\n",
            "\n",
            "DecisionTreeClassifier(class_weight='balanced', max_depth=5, min_samples_leaf=4,\n",
            "                       min_samples_split=20, random_state=1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for algorithm in automl.show_models().items():\n",
        "  print(algorithm[1]['sklearn_classifier'])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQyImPEOLLOr"
      },
      "source": [
        "# Print the best classifier and show the validation accuracy\n",
        "You can check the other classifiers by using `automl.show_models()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-feJD8tiIVbJ",
        "outputId": "813386f5-3e05-47f4-ae76-272916e796fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(criterion='entropy', max_features=15, min_samples_leaf=2,\n",
              "                     min_samples_split=20, n_estimators=512, n_jobs=1,\n",
              "                     random_state=1, warm_start=True)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(list(automl.show_models().values())[0].values())[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Ey4JSh3OWX",
        "outputId": "1901c0f9-dbb9-4e4e-d2d9-1f3f2cf1c5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auto-sklearn results:\n",
            "  Dataset name: sklearn_classification_dataset\n",
            "  Metric: accuracy\n",
            "  Best validation score: 0.810811\n",
            "  Number of target algorithm runs: 24\n",
            "  Number of successful target algorithm runs: 23\n",
            "  Number of crashed target algorithm runs: 0\n",
            "  Number of target algorithms that exceeded the time limit: 1\n",
            "  Number of target algorithms that exceeded the memory limit: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(automl.sprint_statistics())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYvbEjlrLZ-6"
      },
      "source": [
        "# Predict on the test set using the best classifier found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4kzQQvG56wz",
        "outputId": "e2fb5bf3-7a46-4501-fa29-6b8b301e74f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the best classifier: 0.89%\n"
          ]
        }
      ],
      "source": [
        "predictions = automl.predict(x_test)\n",
        "\n",
        "accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy of the best classifier: {round(accuracy,2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n",
        "* https://automl.github.io/auto-sklearn/master/examples/index.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Auto_Sklearn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
